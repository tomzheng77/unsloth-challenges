{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no1bN-PeCfvo"
   },
   "source": [
    "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
    "</div>\n",
    "\n",
    "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Z3tfXwyCfvq"
   },
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hl7_2-51Cfvq"
   },
   "source": [
    "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
    "\n",
    "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VJJ0nwdCfvq"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qoqsmv4_Cfvq",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Skip restarting message in Colab\n",
    "import sys; modules = list(sys.modules.keys())\n",
    "for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
    "\n",
    "!pip install unsloth vllm\n",
    "!pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFIHPJnhCfvr"
   },
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPosm2AeCfvr"
   },
   "source": [
    "Load up `Llama 3.1 8B Instruct`, and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b442106c064f4f8a9a817cff1a9e6a09",
      "eb1d5ab41ee6419da535d92d884dc976",
      "e77ae6216db64a4691b2153fd72db0bc",
      "816eabca92b0491d91b31064cf96c100",
      "9072101b06d44f839e017904359d61bb",
      "60d1dc2a852a4aa0b1d7e846f435ea96",
      "d5aa82a102964b419964a185c8ca2ad2",
      "cc681b56d9a14de89a62634f3ebc540e",
      "3dd33514780a4d8a81b960c4cce395d1",
      "94a96b1749e54663bdfbb42efe3edc47",
      "d3cdadc4fe2640e992465769eecfaa89",
      "b4df74b0aaf54d2d87ed37b382e69075",
      "31859d4a53704768bbe211ef0591ef8b",
      "a1ca1c5aa689408797c0b28428bb845f",
      "368bee030d864252b26a59514a1bc2f0",
      "26b0b590f3874c87a14c9fae4b9e45fc",
      "f8d55094cb674248be01a381ad1c0e90",
      "027e69c7b0b14f1d8e52dc486e0f7ece",
      "6368ddb17d874ebe9902d9a3b1e989ca",
      "40fcbf337187480bb9762ec1238be449",
      "db4db4ef90494cb2af0af1ef83bf07a0",
      "bde1176c108842fe8b4e8b3b368b6802",
      "42dcdb4b9e6847ebb7bd0e125b3b03ab",
      "91d80a0a382c4d2c85c4f74cb34ebfec",
      "52b25acf2ed449a38f6efbeb2bd5124d",
      "e59b54c83cd74f35b5c2d59d9e2cd0e3",
      "9b694fecad474224afedcd48d1937477",
      "85b115b0e4d949828f4741f667c08cc6",
      "9179e2a2108345bc88fe1ef588a193ea",
      "fd2fe1743df042b0abf1781ee8953c6a",
      "4cfa3e8b06d545bd867c896f67bf4529",
      "cce1f26eaca94d2da4337a03c40da5f6",
      "7357ed265f374f128bd168ed32d61aeb",
      "f5080106e93c46568a8171d6fb06788e",
      "948d0894948e4ed491eba3d7d79432e6",
      "3d3c744496064cc4b7fde4595d0e6d01",
      "f8bc8db37ba64465a7c05e41e17a5217",
      "8e5e8778e32045eaaee946c04d62ec73",
      "7548863318254ebcaa85f8093e307020",
      "37e7d761cef94781afff093d2bbdd214",
      "c5dc1fb657f44252a7288bda99047e98",
      "92ab544e8d824f468f56042e064e0dfe",
      "e429d542dd424e9594dab0154748f303",
      "39949be9bc7942c7a82c4183f0775c9d",
      "ad9ba69ef5e2454fb84ecc1f5ea8ebbf",
      "529cf73e101a4a58822a140424b38760",
      "1056a328461b44e6a9c0698892144ddc",
      "82ad106033be4f5a96fb546e713b0db9",
      "8b2f1dc854c043668756dd7fac36566e",
      "94bb590cb0fc44b29bf821048432cb06",
      "dcfd002ca09047ffb081666766034702",
      "e8a46f8d3c194eb9a6eb92e47c37b2b2",
      "080c9df3592c4c84be3f770f2340e2c9",
      "4ce480aeb126448e8d1f09fb69e59fee",
      "5c1f04a3d63446e48d2f3c0670e3f4e7",
      "5575adf210fb4358a9e7a006ab6c7c01",
      "37150d70273941828a0ebd8df8c31a3b",
      "053639347f7f46559b8fb1c8b6e78baa",
      "3adc77a29649429dadfe707510f3128e",
      "8de76c3a0fbe4ef0a6dba9e88d0475d1",
      "4ce90baad86b408596275e631d895743",
      "a1c4b62a913047fa979aef94a5de5306",
      "54716f1fdfa749469cdd3a6d86f429ca",
      "61552dbc623247e0afcfad3c0649af02",
      "6431d703c8b64e81ac36a7aab68bd1a1",
      "e5f076fbec4f49ab8236a9d8b9c27da4",
      "8311bb72b88e43938223846d19ebf234",
      "c06680ce0c834364bab6ec6ed2b60b11",
      "2f1f7b22b20c4509a83e783d70c2d418",
      "a1d4b1044cb042759e0fcfc0357ae458",
      "8c85638338fe4fd9ab2b84a3910d1e05",
      "97bab6a769e74a3cbebf4df906dd915a",
      "0882efd6e5f7494b8727c81a719bc077",
      "4c00e3acab32404cb46588f77e3be3e1",
      "c562f8d2d13542c9b47949e647c21781",
      "3aee8d5b26c142f89665b07f71890293",
      "6b07dae1de7f4d7c8135d6e7ce29144c",
      "9d77ea901a364a258896da39b276f93b",
      "a8bfe353c3c54fc8982ef7db95d6a6bd",
      "1752c76e652e433ab4aa561c5251ab0f",
      "f2ea3ead7ac947469d0df0b5b574949b",
      "280b2b2e781b449880190c26ae23d5b6",
      "dbe079b5ae19497d81b7d60850670205",
      "4867a5a195d74ed48c13239b3ecab86c",
      "ad29aea12ca8436eb99a491b92898c41",
      "cc71450296804b96a06a98b7ca137f4a",
      "bdd20998c75340a8a041906a0cdb1e85",
      "252c13c6a15044649685f86b1ba21069",
      "89f80717c0654ac09b31fdb176d97c87",
      "4c2dd3b21d08428b8259e71d23332eb4",
      "8602b663abd84d2bb6d4ef40f120663f",
      "c3d627a2a16d4bd8a7a7e9c7b2848eaa",
      "bb7686f7a4474f729f212b8987c46729",
      "198cc8afef654f1d829bca2a525f5353",
      "9a600f4ab7e4458fb9249830467ae35e",
      "de71b56096b04ef0aacf9c494b8ca0fe",
      "ecd8493ea1734c01a3b8fe3844b616d0",
      "f56effeb23fc4ce8b097a8a3c6a99983",
      "7e3fedcc6a7f4992b049dc1e2f7dc886",
      "655e443fc4ff4d6d89f17ab7b28256f0",
      "89859633ce2b4e65a62bdc44500cc07f",
      "ff4117dbc50c43138d69891d91c14e72",
      "c1e86da85e504a77a5e4bbb7706adbcd",
      "1107348d5e03439c9ccd64ec1933af01",
      "26b30546dfb94c76aad784e18d867bb2",
      "121e9dcb86e948a98e0324330332418f",
      "1fccb8ff4acd424c90f3a01115c8ebc1",
      "bfc655f4f06e4f2d9e1c0eafe8d23568",
      "61d7c21a1e494fa4845acfeda4de4348",
      "088b4ecbfc9843d3bffe6a579d731f72"
     ]
    },
    "id": "DkIvEkIIkEyB",
    "outputId": "b1a1a04e-a60b-4d68-c492-1a262539d414"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 1024 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/meta-Llama-3.1-8B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.6, # Reduce if out of memory\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KGgPgk_5S8r"
   },
   "source": [
    "### Data Prep\n",
    "<a name=\"Data\"></a>\n",
    "\n",
    "We directly leverage [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) for data prep and all reward functions. You are free to create your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "934ee75d784c4efa9f8189dbf6e975d0",
      "66318341f3d544d7ab55207f2ee09858",
      "3d367f28b8f143edbf22bb6ad716ec88",
      "9fdc28bdddc049b4a5bcb2acfbd50cfe",
      "7703e975d86544efad24928134386f59",
      "9b851c3f098543898adfaeaf32c0c5dd",
      "091ad544d1724a938450525c34a57cd6",
      "70442a4b21b44420ac53f4a58581c6ce",
      "4f9c9864477b42dea8531b55a7f18bec",
      "407158ebc4d2476ea7f568514dded087",
      "57dc0f5b690e48dcb8b48c805263e4ee",
      "1905d9262b194058892a694c41461265",
      "3b1dd910519d473582391f9c02699e01",
      "d16cb3e105394df8b2e5d93e436d481c",
      "79ef95512eef4bb68e9cf32f107e7a6d",
      "1a57b77de6e64e4f89ee6635b872224d",
      "b88e5bb2da8d41aa87e355a0c453f34e",
      "966c8f397a16452a83433343b339b9c6",
      "5308ad4485494c349c906884d7371a8e",
      "b2e37f5277fc4043a45b4089a93ec704",
      "a35260ca423f4fe98879180b3ef30e5a",
      "70d4c0fa48124d2788ab52d38231929c",
      "d8e8273d9386473ea8602801c3bfa6cd",
      "673e47ffffbb4708b8b732b2b5336244",
      "3a3709c9faf34462a42bd95561d8de82",
      "22a7842c6d5749aaa7b88b5211267744",
      "2eaadeb9665c4e4e95cf66c1ba83daa2",
      "c94235bb672d428f87829440fd5b31a8",
      "bd744f8c9191403589178524b00ad132",
      "629f0d4326c94c0e8e9384cd099ad372",
      "d7775814fac54ed896d4b0d402221852",
      "6270e5b7903a40db87980f6a23c22af6",
      "486ad3e3bf6e4839a84544d2d4e3c396",
      "4acf5b037b63482fa3dd1b733f6aed08",
      "e38ae383762e4ac09ac60174669ba95a",
      "9a19ec1de0a04edda01e776842c2b0b8",
      "57c799954184424aa77586dc0b7e520e",
      "4dd744d786604774818e38cf60764cda",
      "c310e75610034060b8d7b8059066e401",
      "8c7e289bff7040d0bee0222781354560",
      "6cd4a98300c14cac81f7c473dbba3ca9",
      "7c799821011f4f5986a2bc7cf7a9146e",
      "e4ce496df3d9461884e63fcc644c6150",
      "17ed832fce854bb296ec13882883774f",
      "7208103b293d4d94963800a6a8c1cbfa",
      "dfd33222f38c497fbf7ebc566192adae",
      "130e5803640b4ce1a0c39c96ad8df7fa",
      "f9d07aaace42482f99aac69beff776da",
      "55845a8338714455a9d4594b44646b97",
      "204e3185ecec4d5399a81872ea5674bf",
      "bcfbb7f5aed3406cad27c79599f66486",
      "2c9f38162a0c48e1a572ab1c67bbd1a9",
      "cbf0fdaa7f5b42388ca9e2158ec9a67b",
      "78cc88fcb2a647149a486cdb8a0b0031",
      "16191c32bd0c4434848d6ee621d440f3",
      "f7043752ba6f4c588b995b445b96fa0e",
      "7d2a6e5635fd4bc4ae05ec4fb0e8c545",
      "423a883032084f8cbc981117dd64f16f",
      "d67ccb3e27964f9aa2c724650b197ddd",
      "5277096adde743d8a9db3d96882326c9",
      "9b714fe2e7a34726a6b87ad068745aea",
      "b4e1c2e9767246d89e97f1a44a50b9a8",
      "455084ae7b504290a26124c94e76261e",
      "c1cb935ef742467f8fbab9a800e28378",
      "604eaa17af4f4b80b5f6e5fde782c13c",
      "62cb5278df874c87ab8b0eff0ba857ec"
     ]
    },
    "id": "cXk993X6C2ZZ",
    "outputId": "66d0c9aa-4a14-4694-c1ee-d23a0572cb72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Load and prep dataset\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "# uncomment middle messages for 1-shot prompting\n",
    "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
    "    data = data.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer'])\n",
    "    }) # type: ignore\n",
    "    return data # type: ignore\n",
    "\n",
    "dataset = get_gsm8k_questions()\n",
    "\n",
    "# Reward functions\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "def int_reward_func(completions, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux6iqP7z5YOo"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "\n",
    "Now set up GRPO Trainer and all configurations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptqkXK2D4d6p",
    "outputId": "a2fa9a53-6c36-4b2d-ce98-9d024be1b1eb"
   },
   "outputs": [],
   "source": [
    "max_prompt_length = 256\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
    "    num_generations = 6, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 250,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9Mv8UZO5hz-"
   },
   "source": [
    "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
    "\n",
    "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
    "\n",
    "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
    "|------|---------------|-----------|------------|-------------------|----------|\n",
    "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
    "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
    "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vzOuSVCL_GA9",
    "outputId": "8a3dd840-6741-44d3-c30c-b0b2a8c055ce"
   },
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        xmlcount_reward_func,\n",
    "        soft_format_reward_func,\n",
    "        strict_format_reward_func,\n",
    "        int_reward_func,\n",
    "        correctness_reward_func,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlaUdxC_VHpz"
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtcz_lpbVC92"
   },
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    [text],\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = None,\n",
    ")[0].outputs[0].text\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Colxz9TAVMsi"
   },
   "source": [
    "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AL-BcuB1VLIv"
   },
   "outputs": [],
   "source": [
    "model.save_lora(\"grpo_saved_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwpbwnDBVRLg"
   },
   "source": [
    "Now we load the LoRA and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zf_OY5WMVOxF"
   },
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
    "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    text,\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
    ")[0].outputs[0].text\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aDgFfhFYIAS"
   },
   "source": [
    "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NUEmHFSYNTp"
   },
   "source": [
    "<a name=\"Save\"></a>\n",
    "### Saving to float16 for VLLM\n",
    "\n",
    "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjXGTkp7YNtB"
   },
   "outputs": [],
   "source": [
    "# Merge to 16bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
    "\n",
    "# Merge to 4bit\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# Just LoRA adapters\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
    "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52WMb3k_YPt8"
   },
   "source": [
    "### GGUF / llama.cpp Conversion\n",
    "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
    "\n",
    "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
    "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
    "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
    "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
    "\n",
    "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyEjW-WuYQIm"
   },
   "outputs": [],
   "source": [
    "# Save to 8bit Q8_0\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
    "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
    "# And change hf to your username!\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
    "\n",
    "# Save to 16bit GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
    "\n",
    "# Save to q4_k_m GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
    "\n",
    "# Save to multiple GGUF options - much faster if you want multiple!\n",
    "if False:\n",
    "    model.push_to_hub_gguf(\n",
    "        \"hf/model\", # Change hf to your username!\n",
    "        tokenizer,\n",
    "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
    "        token = \"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbwkFwygCfvx"
   },
   "source": [
    "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
    "\n",
    "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
    "\n",
    "Some other links:\n",
    "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
    "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
    "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
    "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
    "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
    "\n",
    "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
